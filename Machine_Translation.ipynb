{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gS4qlwl6zFGh",
        "rWS6QJMHzg_Y",
        "heOZjAE-z7tc",
        "pIi2IXs41dup",
        "3yhEv3FgUVf5",
        "acFqhgV6XNv6",
        "dhE7nZlejlTQ",
        "AKdzhE2l8SkM",
        "hk7m4KVEwnoV",
        "lMP_EMA23GK1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing nessesary libraries"
      ],
      "metadata": {
        "id": "gS4qlwl6zFGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch"
      ],
      "metadata": {
        "id": "yrkHXdC81qPQ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing data"
      ],
      "metadata": {
        "id": "rWS6QJMHzg_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w0NMwSBeyt3F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file\n",
        "import pathlib\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuaSmQ_by3l0",
        "outputId": "04056137-bfd2-4c28-8c88-47504f9fa899"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  text = path.read_text(encoding='utf-8')\n",
        "\n",
        "  lines = text.splitlines()\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "\n",
        "  context = np.array([context for target, context in pairs])\n",
        "  target = np.array([target for target, context in pairs])\n",
        "\n",
        "  return target, context"
      ],
      "metadata": {
        "id": "PMpeuVQBy3tz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_raw, context_raw = load_data(path_to_file)"
      ],
      "metadata": {
        "id": "7G4r6hT_y6TY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = -1\n",
        "print(target_raw[idx])\n",
        "print(context_raw[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFqQUl2nzkpk",
        "outputId": "38a5649e-49ce-40ab-cc03-23845fe52327"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n",
            "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing: Text normalization"
      ],
      "metadata": {
        "id": "heOZjAE-z7tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_unicode(text, normalization_form='NFC'):\n",
        "    normalized_text = unicodedata.normalize(normalization_form, text)\n",
        "    return normalized_text"
      ],
      "metadata": {
        "id": "9bPJIh2W1hsS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(text_array):\n",
        "    return_array = []\n",
        "    for sentence in text_array:\n",
        "        sentence = sentence.lower()\n",
        "        sentence = normalize_unicode(sentence)\n",
        "        sentence = sentence.replace('.', '')\n",
        "        return_array.append(sentence)\n",
        "    return np.array(return_array)"
      ],
      "metadata": {
        "id": "0UXzyl7M105B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of context raw: {len(context_raw)}\")\n",
        "print(f\"Length of target raw: {len(target_raw)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpJBw4AU1xyT",
        "outputId": "ba4c4fd3-ad6d-4e06-da1e-dacf1ae3a0d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of context raw: 118964\n",
            "Length of target raw: 118964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = normalize(context_raw)\n",
        "target = normalize(target_raw)"
      ],
      "metadata": {
        "id": "YuFKc8Br2cR2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd0qdEK4266m",
        "outputId": "dfe3ac09-0be7-4203-8780-0e9cf298a400"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ve', 'vete', 'vaya', ...,\n",
              "       'una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático',\n",
              "       'como suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes simplemente voy a la siguiente página encontrada por google y espero encontrar algo menos irritante',\n",
              "       'si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado'],\n",
              "      dtype='<U276')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DbTga_N3BH9",
        "outputId": "e6407c9e-7af8-4e66-bdef-944a6173b49b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ve.', 'Vete.', 'Vaya.', ...,\n",
              "       'Una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático.',\n",
              "       'Como suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a la siguiente página encontrada por Google y espero encontrar algo menos irritante.',\n",
              "       'Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.'],\n",
              "      dtype='<U278')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of context preprocessed: {len(context)}\")\n",
        "print(f\"Length of target preprocessed: {len(target)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5d-G5-n2hOL",
        "outputId": "353697a6-3820-43d2-d38c-f1512db6acb2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of context preprocessed: 118964\n",
            "Length of target preprocessed: 118964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing: Vectorization"
      ],
      "metadata": {
        "id": "pIi2IXs41dup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN = 0\n",
        "PAD_TOKEN = 1\n",
        "END_TOKEN = 2\n",
        "UNK_TOKEN = 3"
      ],
      "metadata": {
        "id": "lFJgFbRJz62I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, text_array, freq=2):\n",
        "        self.text_array = text_array\n",
        "        self.ttov = {\"<sos>\": START_TOKEN, \"<pad>\": PAD_TOKEN,\n",
        "                     \"<eos>\": END_TOKEN, \"<unk>\": UNK_TOKEN}\n",
        "        self.vtot = dict((idx, token) for token, idx in self.ttov.items())\n",
        "        self.length = 4\n",
        "        self.counter = Counter()\n",
        "        self.freq = freq\n",
        "        self.build_vocab()\n",
        "\n",
        "    def add(self, token):\n",
        "        self.ttov[token] = self.length\n",
        "        self.vtot[self.length] = token\n",
        "        self.length += 1\n",
        "\n",
        "    def build_vocab(self):\n",
        "        for sentence in self.text_array:\n",
        "            for token in sentence.split():\n",
        "                self.counter.update([token])\n",
        "\n",
        "        for token, counter in self.counter.items():\n",
        "            if counter >= self.freq:\n",
        "                self.add(token)\n",
        "\n",
        "    def vecToText(self, vec):\n",
        "        text = []\n",
        "        for v in vec:\n",
        "            if v in self.vtot:\n",
        "                text.append(self.vtot[v])\n",
        "            else:\n",
        "                text.append(\"<unk>\")\n",
        "        return torch.tensor(text)\n",
        "\n",
        "    def textToVec(self, text):\n",
        "        vec = []\n",
        "        for t in text:\n",
        "            if t in self.ttov:\n",
        "                vec.append(self.ttov[t])\n",
        "            else:\n",
        "                vec.append(UNK_TOKEN)\n",
        "        return torch.tensor(vec)"
      ],
      "metadata": {
        "id": "Y0h36Tdc0rPi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vocab = Vocab(context)\n",
        "target_vocab = Vocab(target)"
      ],
      "metadata": {
        "id": "uT7sDYkA0rYK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of context dictionary: {context_vocab.length}\")\n",
        "print(f\"Length of target dictionary: {target_vocab.length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2K6Ihqb0w6n",
        "outputId": "37a92cb6-89f9-4f78-9049-1cd1e6c068c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of context dictionary: 18169\n",
            "Length of target dictionary: 11401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "3yhEv3FgUVf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, context_array, target_array, context_vocab, target_vocab):\n",
        "        if len(context_array) != len(target_array):\n",
        "            raise ValueError(\"Lengths of context and target must be equal.\")\n",
        "        self.context = context_array\n",
        "        self.target = target_array\n",
        "        self.context_vocab = context_vocab\n",
        "        self.target_vocab = target_vocab\n",
        "        self.length = len(context_array)\n",
        "        self.context_max_length = self.getMaxLen(self.context)\n",
        "        self.target_max_length = self.getMaxLen(self.target)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context = self.context_vocab.textToVec(self.context[idx].split())\n",
        "        target = self.target_vocab.textToVec(self.target[idx].split())\n",
        "        return context, target\n",
        "\n",
        "    def getMaxLen(self, text_array):\n",
        "        return len(max(self.context, key=lambda x: len(x.split())).split())"
      ],
      "metadata": {
        "id": "JdsVnYAJ0xBM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = TextDataset(context, target, context_vocab, target_vocab)\n",
        "data.__getitem__(333)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQDYSQV67Vjj",
        "outputId": "e59ff2e8-e8be-46f7-a604-2e1b99f26bc3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([142, 311]), tensor([ 40, 192]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_MAX_LENGTH = data.context_max_length\n",
        "TARGET_MAX_LENGTH = data.target_max_length\n",
        "print(f\"Maximum length of context: {CONTEXT_MAX_LENGTH}\")\n",
        "print(f\"Maximum length of target: {TARGET_MAX_LENGTH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUFATLRmJNnd",
        "outputId": "14c3a101-f843-44d0-f99a-7b66d6edb5a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length of context: 49\n",
            "Maximum length of target: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "acFqhgV6XNv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    context, target = [data[0] for data in batch], [data[1] for data in batch]\n",
        "    target_in = [torch.cat([torch.tensor([START_TOKEN]), text]) for text in target]\n",
        "    target_out = [torch.cat([text, torch.tensor([END_TOKEN])]) for text in target]\n",
        "    return pad(context, CONTEXT_MAX_LENGTH), pad(target_in, TARGET_MAX_LENGTH), pad(target_out, TARGET_MAX_LENGTH)\n",
        "\n",
        "def pad(texts, max_len):\n",
        "    padded = []\n",
        "    for text in texts:\n",
        "        while len(text) < max_len:\n",
        "            text = torch.cat([text, torch.tensor([PAD_TOKEN])])\n",
        "        padded.append(text)\n",
        "    return torch.stack(padded)"
      ],
      "metadata": {
        "id": "lWpbR61CXPDM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = DataLoader(data, batch_size=32, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "EQmTlpwoXPNw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(d))\n",
        "print(f\"Shape of context: {batch[0].shape}\")\n",
        "print(f\"Shape of target input: {batch[1].shape}\")\n",
        "print(f\"Shape of target output: {batch[2].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "185xtfXqXPZJ",
        "outputId": "dfe83c76-7717-4051-8112-8ed2d9b7a0c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of context: torch.Size([32, 49])\n",
            "Shape of target input: torch.Size([32, 49])\n",
            "Shape of target output: torch.Size([32, 49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder model"
      ],
      "metadata": {
        "id": "dhE7nZlejlTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# B: Batch size\n",
        "# L: Max length\n",
        "# E: Embedding size\n",
        "# H: Hidden size\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embed_size, vocab_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=PAD_TOKEN)\n",
        "        self.rnn = nn.GRU(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, context):\n",
        "        # Context: [B, L]\n",
        "        x = self.embedding(context) # [B, L, E]\n",
        "        x, h = self.rnn(x)  # x: [B, L, 2*H], h: [2, B, H]\n",
        "        h = torch.cat([h[0:1], h[1:2]], dim=2)\n",
        "        return x, h # x: [B, L, 2*H], h: [1, B, 2*H]"
      ],
      "metadata": {
        "id": "_9WyklBrjm33"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = context_vocab.length\n",
        "embed_size = 300\n",
        "hidden_size = 200"
      ],
      "metadata": {
        "id": "eHFeJ3k2tTzQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(embed_size, vocab_size, hidden_size)"
      ],
      "metadata": {
        "id": "hs16i4Aruy6t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of context: {batch[0].shape}\")\n",
        "result = encoder.forward(batch[0])\n",
        "print(f\"Shape of encoder output: {result[0].shape}\")\n",
        "print(f\"Shape of hidden state: {result[1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G8SAJVmuzDH",
        "outputId": "6daf5738-0efd-4a78-e6d2-159e88ff5846"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of context: torch.Size([32, 49])\n",
            "Shape of encoder output: torch.Size([32, 49, 400])\n",
            "Shape of hidden state: torch.Size([1, 32, 400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention layer"
      ],
      "metadata": {
        "id": "AKdzhE2l8SkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.Q = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.K = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.V = nn.Linear(hidden_size * 2, 1)\n",
        "\n",
        "    # Query: RNN decoder hidden state: [B, 1, 2*H]\n",
        "    # Key: Encoder output: [B, L, 2*H]\n",
        "    # Value: Encoder output: [B, L, 2*H]\n",
        "    def forward(self, query, key):\n",
        "        x = self.V(torch.tanh(self.Q(query) + self.K(key))) #[B, L, 1]\n",
        "        x = x.squeeze(2).unsqueeze(1) #[B, 1, L]\n",
        "        weights = F.softmax(x, dim=-1)\n",
        "        context = torch.bmm(weights, key) #[B, 1, 2*H]\n",
        "        return weights, context"
      ],
      "metadata": {
        "id": "n1cZ8NdhSZ4Z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn = Attention(hidden_size)\n",
        "query = result[1].permute(1, 0, 2)\n",
        "key = result[0]\n",
        "print(f\"Shape of query: {query.shape} and shape of key: {key.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuqpxpmPSHSO",
        "outputId": "6a6eacc1-bedc-491b-de41-20d14f830f60"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of query: torch.Size([32, 1, 400]) and shape of key: torch.Size([32, 49, 400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights, context = attn.forward(query, key)\n",
        "print(f\"Shape of weights: {weights.shape} and shape of context: {context.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pp7V0ZwT2vE",
        "outputId": "7246fde7-90e0-484b-e1e0-9f20a5463c31"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of weights: torch.Size([32, 1, 49]) and shape of context: torch.Size([32, 1, 400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder model"
      ],
      "metadata": {
        "id": "hk7m4KVEwnoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embed_size, vocab_size, hidden_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=PAD_TOKEN)\n",
        "        self.attention = Attention(hidden_size)\n",
        "        self.rnn = nn.GRU(embed_size + 2 * hidden_size, hidden_size * 2, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size * 2, vocab_size)\n",
        "\n",
        "    def forward(self, encoder_out, hidden_init, target_in):\n",
        "        decoder_hidden = hidden_init #[1, B, 2*H]\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for t in range(TARGET_MAX_LENGTH):\n",
        "            decoder_in = target_in[:, t].unsqueeze(1) #[B, 1]\n",
        "            output, decoder_hidden, weights = self.forward_step(encoder_out, decoder_hidden, decoder_in)\n",
        "            decoder_outputs.append(output)\n",
        "            attentions.append(weights)\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "        logits = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "    def forward_step(self, encoder_out, decoder_hidden, decoder_in):\n",
        "        token_embedded = self.embedding(decoder_in) #[B, 1, E]\n",
        "        weights, context = self.attention(query=decoder_hidden.permute(1, 0, 2), key=encoder_out) #[B, 1, L], [B, 1, 2*H]\n",
        "        gru_input = torch.concat([token_embedded, context], dim=2) #[B, 1, E+2*H]\n",
        "        output, decoder_hidden = self.rnn(gru_input, decoder_hidden) #[B, 1, 2*H], [B, 1, 2*H]\n",
        "        output = self.out(output) #[B, 1, 2*H]\n",
        "        return output, decoder_hidden, weights #[B, 1, V], [1, B, 2*H]"
      ],
      "metadata": {
        "id": "FoZLsjp_wppt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(embed_size, vocab_size, hidden_size)"
      ],
      "metadata": {
        "id": "oHIUKwglsKOt"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_out = result[0]\n",
        "hidden_init = result[1]\n",
        "target_in = batch[1]\n",
        "target_out = batch[2]\n",
        "print(f\"Shape of encoder output: {encoder_out.shape} and initial hidden vector: {hidden_init.shape}\")\n",
        "print(f\"Shape of target input: {target_in.shape} and target output: {target_out.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeIrTUvhsKUK",
        "outputId": "de5ef8f4-af1e-491f-8c59-5309fc4690b5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of encoder output: torch.Size([32, 49, 400]) and initial hidden vector: torch.Size([1, 32, 400])\n",
            "Shape of target input: torch.Size([32, 49]) and target output: torch.Size([32, 49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_outputs, decoder_hidden, attentions = decoder.forward(encoder_out, hidden_init, target_in)"
      ],
      "metadata": {
        "id": "pC_HmsQ_sKZe"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of decoder output: {decoder_outputs.shape}\")\n",
        "print(f\"Shape of decoder hidden: {decoder_hidden.shape}\")\n",
        "print(f\"Shape of attention weights: {attentions.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofi0obqotzFk",
        "outputId": "76c50365-1455-4fe3-a7c6-cc970d2bdc48"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of decoder output: torch.Size([32, 49, 18169])\n",
            "Shape of decoder hidden: torch.Size([1, 32, 400])\n",
            "Shape of attention weights: torch.Size([32, 49, 49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation model"
      ],
      "metadata": {
        "id": "Tyo3sXkpuS5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, input_vocab_size, output_vocab_size):\n",
        "        super(Translator, self).__init__()\n",
        "        self.encoder = Encoder(embed_size, input_vocab_size, hidden_size)\n",
        "        self.decoder = Decoder(embed_size, output_vocab_size, hidden_size)\n",
        "\n",
        "    def forward(self, context, target_in):\n",
        "        encoder_out, hidden_init = self.encoder.forward(context)\n",
        "        decoder_out, decoder_hidden, attentions = self.decoder.forward(encoder_out, hidden_init, target_in)\n",
        "        return decoder_out, decoder_hidden, attentions"
      ],
      "metadata": {
        "id": "geVxjbE8t_hY"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = context_vocab.length\n",
        "output_vocab_size = target_vocab.length\n",
        "embed_size = 300\n",
        "hidden_size = 200"
      ],
      "metadata": {
        "id": "H1l3eaCixNl4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Translator(embed_size, hidden_size, input_vocab_size, output_vocab_size)"
      ],
      "metadata": {
        "id": "vgxcIfZOxYxU"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context, target_in, target_out = batch\n",
        "print(f\"Context shape: {context.shape}\")\n",
        "print(f\"Target input shape: {target_in.shape}\")\n",
        "print(f\"Target output shape: {target_out.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Xpohsoxdla",
        "outputId": "b74df2fc-8206-4cd2-d7fe-08e608028fe5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context shape: torch.Size([32, 49])\n",
            "Target input shape: torch.Size([32, 49])\n",
            "Target output shape: torch.Size([32, 49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_out, decoder_hidden, attentions = model.forward(context, target_in)"
      ],
      "metadata": {
        "id": "pRITjhlnxsM5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of decoder output: {decoder_out.shape}\")\n",
        "print(f\"Shape of decoder hidden: {decoder_hidden.shape}\")\n",
        "print(f\"Shape of attention weights: {attentions.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8MIiRLsxwBG",
        "outputId": "95cf50f2-7927-4e3c-9b7b-5f72ade065a7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of decoder output: torch.Size([32, 49, 11401])\n",
            "Shape of decoder hidden: torch.Size([1, 32, 400])\n",
            "Shape of attention weights: torch.Size([32, 49, 49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "Rp81w4KSwAyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, optimizer, criterion, num_epochs, val_data=None):\n",
        "\n",
        "    av_loss = []\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        total_loss = 0\n",
        "        count = 0\n",
        "        val_data = iter(val_data) if val_data is not None else None\n",
        "\n",
        "        for context, target_in, target_out in train_data:\n",
        "            optimizer.zero_grad()\n",
        "            logits, hidden, attentions = model.forward(context, target_in)\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target_out.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss\n",
        "            print(f\"Training loss: {loss.item()}\") if count % 10 == 0 else None\n",
        "            print(f\"Logits contain nan\") if torch.isnan(logits).any().item() else None\n",
        "\n",
        "            if count % 50 == 0:\n",
        "                if val_data is not None:\n",
        "                    context, target_in, target_out = next(val_data)\n",
        "                    logits, hidden, attentions = model.forward(context, target_in)\n",
        "                    loss = criterion(logits.view(-1, logits.size(-1)), target_out.view(-1))\n",
        "                    print(f\"Validation loss: {loss.item()}\")\n",
        "\n",
        "            count += 1\n",
        "        print(f\"Epoch {epoch} with average loss {total_loss / count} --------------------------------------------\")\n",
        "        av_loss.append(total_loss / count)\n",
        "    return av_loss"
      ],
      "metadata": {
        "id": "Iw8A-5SAt_rK"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training preparations"
      ],
      "metadata": {
        "id": "lMP_EMA23GK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_raw, context_raw = load_data(path_to_file)\n",
        "context = normalize(context_raw)\n",
        "target = normalize(target_raw)\n",
        "print(f\"Length of preprocessed context: {len(context)}\")\n",
        "print(f\"Length of preprocessed target: {len(target)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7msfi4t4vXq",
        "outputId": "2a7f53b0-52cb-4b5f-fa08-fd409bad8cbc"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of preprocessed context: 118964\n",
            "Length of preprocessed target: 118964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(context, target, context_vocab, target_vocab)\n",
        "CONTEXT_MAX_LENGTH = dataset.context_max_length\n",
        "TARGET_MAX_LENGTH = dataset.target_max_length\n",
        "print(f\"Maximum length of context: {CONTEXT_MAX_LENGTH}\")\n",
        "print(f\"Maximum length of target: {TARGET_MAX_LENGTH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az_A0uso4ZVD",
        "outputId": "628c7abb-fd8f-43b3-81d9-407d2bc933f9"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length of context: 49\n",
            "Maximum length of target: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size of dataset: {len(dataset)}\")\n",
        "train_ratio, val_ratio = 0.6, 0.2\n",
        "train_size, val_size = int(len(dataset) * train_ratio), int(len(dataset) * val_ratio)\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "print(f\"Size of training data: {train_size}, validation data: {val_size}, test_data: {test_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDQa9opu5Ge8",
        "outputId": "c903c656-16a3-4a78-ae9e-7516a997724a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of dataset: 118964\n",
            "Size of training data: 71378, validation data: 23792, test_data: 23794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "7Yj7tNa95z8P"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "5UUUCqou6Ezf"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = context_vocab.length\n",
        "output_vocab_size = target_vocab.length\n",
        "embed_size = 400\n",
        "hidden_size = 256"
      ],
      "metadata": {
        "id": "kOWPTNFU6s9_"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "3GnnFtqH6ZSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Translator(embed_size, hidden_size, input_vocab_size, output_vocab_size)"
      ],
      "metadata": {
        "id": "2K2ExVW76pXx"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2"
      ],
      "metadata": {
        "id": "CI5nMWFW7B2_"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train(model, train_dataloader, optimizer, criterion, 2, val_data=val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUkaWETU6azQ",
        "outputId": "eff5ece4-8f8b-4fe3-dc36-d539818836b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.019107336178421974\n",
            "Validation loss: 0.019121477380394936\n",
            "Training loss: 0.023945514112710953\n"
          ]
        }
      ]
    }
  ]
}